{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e78804",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2e1318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import ee\n",
    "import geemap\n",
    "import folium\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from modules.json_to_ee import json_to_feature_with_id\n",
    "import modules.agstack_to_gee as agstack_to_gee\n",
    "import modules.area_stats as area_stats\n",
    "import modules.tidy_tables as tidy_tables\n",
    "\n",
    "from parameters import * # for run-specific parameters edit \"parameters/config_runtime\"\n",
    "\n",
    "print (\"imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae87ed9-f4e4-4a98-81df-e66e17aa77f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c76fb-f3ba-43cf-a918-4f6d09e43a7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Grab datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae98294-9c98-4b31-b44a-c617f3613228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing image collection asset\n"
     ]
    }
   ],
   "source": [
    "if use_existing_image_collection:\n",
    "    images_IC = ee.ImageCollection(\"users/andyarnell10/fdap_dpi/imageCol_trial_2\")\n",
    "    print (\"using existing image collection asset\")\n",
    "else:\n",
    "    from dataset_properties.set_image_properties import images_IC\n",
    "    print (\"compiling image collection on the fly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56875dab-d0f1-4c00-b552-1e7e0d43c0b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Fetch some fields (public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00c5d0-b739-4605-af7c-589920a7c962",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Transform geometries into a feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d06656-77ce-43d2-baa3-c111724d22e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0520cfac98fbc1bd7952b1c07a9f6983b83625722b6f665ea83ac9aad3512918', 'b84f55de2b7f3c77d1cbeb8b026a1b29be42d8b08d92058c9143e0556456820f', 'b7c15efb6e3c63fcfe649a2d994973a6f5caa844f720f0edb7cf24f6a6c3c1b3', 'fa2aff0d60cf1bc0e1f1dd4b91daf932940c31c021ca1b84f5b9445855eef02f', '88bec54ad04804f5b1fafbc131266640a129be2840fa6797cda358d7e831b907', 'ef2f7c46fbe4fc892fdb81f9a31c9c507b9f1e4548504247dcbbab28cf8e436c', '97408ef7bdac487e4a42e4abf20492b786310889fd4b0478603e2d0004c40bfb', 'c288d6c94efa9011c0e3452af9f7fa0941661377030e10d29c68764617f9816d', '1a41a309ae2387f36a604c9a6c81887e64357a7f61d228758e23ef766286fcd7', '1a4472dc40700ef33f931863f58d444f243d64418616678fcf85c57e1f4bbf45', '8e2accea7ddbb84b7f6001e00bcb60f57f563c80633b53859993522a6f05727a']\n"
     ]
    }
   ],
   "source": [
    "CIV_ids = ['0520cfac98fbc1bd7952b1c07a9f6983b83625722b6f665ea83ac9aad3512918',\n",
    "           'b84f55de2b7f3c77d1cbeb8b026a1b29be42d8b08d92058c9143e0556456820f',\n",
    "           'b7c15efb6e3c63fcfe649a2d994973a6f5caa844f720f0edb7cf24f6a6c3c1b3',\n",
    "            'fa2aff0d60cf1bc0e1f1dd4b91daf932940c31c021ca1b84f5b9445855eef02f']\n",
    "\n",
    "GHA_ids = ['88bec54ad04804f5b1fafbc131266640a129be2840fa6797cda358d7e831b907', \n",
    "'ef2f7c46fbe4fc892fdb81f9a31c9c507b9f1e4548504247dcbbab28cf8e436c',\n",
    "'97408ef7bdac487e4a42e4abf20492b786310889fd4b0478603e2d0004c40bfb']\n",
    "\n",
    "IDN_ids = ['c288d6c94efa9011c0e3452af9f7fa0941661377030e10d29c68764617f9816d', \n",
    "       '1a41a309ae2387f36a604c9a6c81887e64357a7f61d228758e23ef766286fcd7',\n",
    "       '1a4472dc40700ef33f931863f58d444f243d64418616678fcf85c57e1f4bbf45',\n",
    "       '8e2accea7ddbb84b7f6001e00bcb60f57f563c80633b53859993522a6f05727a']\n",
    "\n",
    "all_geo_ids= CIV_ids+GHA_ids+IDN_ids\n",
    "\n",
    "if debug: print (all_geo_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01f69c-6715-4f03-9552-ee22a7467c27",
   "metadata": {},
   "source": [
    "#### Asset registry: start session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc6759-b967-41aa-88bb-cdb687b68a29",
   "metadata": {},
   "source": [
    "NB this is timing out so skipping section - seems to work without somehow. Maybe an open connection already..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6fe913-051a-44fe-a186-ff6ea9cebf4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RequestsCookieJar[]>\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "## using session to store cookies that are persistent\n",
    "session = requests.session()\n",
    "session.headers = headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "req_body = {'email': email, 'password': password}\n",
    "res = session.post(user_registry_base, json=req_body)\n",
    "if debug: print (session.cookies)\n",
    "if debug: print (res.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040debff-4f8a-44d2-91f6-8a8ab79aff3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fetch features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828017fa-9522-406c-8f8d-18a67aee3c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of geo ids in list:  11\n",
      "Count of features in FeatureCollection:  11\n"
     ]
    }
   ],
   "source": [
    "#is there a list of geo_ids\n",
    "if isinstance(all_geo_ids, list):\n",
    "    multiple_inputs=True\n",
    "elif isinstance(all_geo_ids, str):\n",
    "    multiple_inputs=False\n",
    "else:\n",
    "    print (\"Input must be a single string or list of strings\")\n",
    "\n",
    "#if list of geo ids, loop over them and make a feature collection else jsut put as a single feature in a feature collection\n",
    "if multiple_inputs==True:\n",
    "    roi = agstack_to_gee.geo_id_list_to_feature_collection(all_geo_ids,geo_id_column, session,asset_registry_base)    \n",
    "    if debug: print (\"Count of geo ids in list: \", len(all_geo_ids))\n",
    "    \n",
    "elif multiple_inputs == False: \n",
    "    roi = ee.FeatureCollection(agstack_to_gee.geo_id_to_feature(all_geo_ids,geo_id_column, session,asset_registry_base))\n",
    "    if debug: print (\"Geo id input: \", all_geo_ids)\n",
    "else: \n",
    "    print(\"no ee.Object created: check input format\")\n",
    "\n",
    "if debug: print (\"Count of features in FeatureCollection: \", roi.size().getInfo())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f44941-3245-42ba-becb-3472af5c29a8",
   "metadata": {},
   "source": [
    "#### Feature prep\n",
    "- Create additional buffer zones for deforestation risk \n",
    "- Add area property to feature(s) \n",
    "- Select only columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14f2cc9-a2a8-4fb7-a97f-d58ca72fe45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi = area_stats.add_area_hectares_property_to_feature_collection(roi,geometry_area_column)\n",
    "\n",
    "roi  = roi.select([geometry_area_column,geo_id_column]) ##select only fields of interest\n",
    "\n",
    "roi_alerts_buffer = roi.map(lambda feature: \n",
    "        feature.buffer(local_alerts_buffer_radius,max_error_alert_buff))\n",
    "\n",
    "# if debug: geemap.ee_to_pandas(roi_alerts_buffer)\n",
    "# if debug: geemap.ee_to_pandas(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874274c3-15af-4aca-b407-f7683f883878",
   "metadata": {},
   "source": [
    "#### 3) Compute statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f19d47-119d-4df0-b156-cdc2ab2e3e69",
   "metadata": {},
   "source": [
    "Calculating zonal statistics for continuous data (e.g tree cover) within polygon(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce375a3-ac9a-4fb8-b61f-0604e8c50f30",
   "metadata": {},
   "source": [
    "##### i) Mapping over image collection with reduce regions: creates long format raw stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb541ae-5d09-41a0-9f76-f95de256e2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_buffer_stats_list = list(lookup_gee_datasets[\"dataset_name\"][(lookup_gee_datasets[\"local_buffer\"]==1)])\n",
    "\n",
    "flag_list = list(lookup_gee_datasets[\"dataset_name\"][(lookup_gee_datasets[\"presence_only_flag\"]==1)])\n",
    "\n",
    "country_allocation_stats_only_list = list(lookup_gee_datasets[\"dataset_name\"][(lookup_gee_datasets[\"country_allocation_stats_only\"]==1)])\n",
    "\n",
    "all_dataset_list = list(lookup_gee_datasets[\"dataset_name\"])\n",
    "\n",
    "remove_list = country_allocation_stats_only_list+local_buffer_stats_list\n",
    "\n",
    "normal_poly_stats_list = [i for i in all_dataset_list if i not in remove_list] # remove country stats (as mode only) and remove buffer stats (assuming buffer only - NB this may change)\n",
    "\n",
    "decimal_place_column_list =  [i for i in all_dataset_list if i not in flag_list + country_allocation_stats_only_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9cbfcd-fc1f-4516-b455-e2d88c4b7461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing stats...\n",
      "Total execution time: 2.1421597003936768 seconds\n"
     ]
    }
   ],
   "source": [
    "# get the start time\n",
    "st = time.time()\n",
    "if debug: print (\"processing stats...\")\n",
    "\n",
    "## reducer choice for zonal statistics\n",
    "reducer_choice = ee.Reducer.sum().combine(  #main stats based on area of pixel\n",
    "  reducer2=ee.Reducer.count(),sharedInputs=True).combine(reducer2=ee.Reducer.mode(), sharedInputs=True) ##mode used for country allocation (majority pixel count on country code raster)\n",
    "\n",
    "# #get stats for roi (except alerts)\n",
    "fc_stats_combined = area_stats.reduceStatsIC(roi,\n",
    "                                  images_IC.filter(ee.Filter.inList(\"system:index\",normal_poly_stats_list)),\n",
    "                                                                  reducer_choice)# all but alerts\n",
    "# #get stat for buffer (alerts only)\n",
    "fc_stats_combined_buffer = area_stats.reduceStatsIC(roi_alerts_buffer,\n",
    "                                                    images_IC.filter(ee.Filter.inList(\"system:index\",local_buffer_stats_list)),\n",
    "                                                    reducer_choice) #alerts only\n",
    "\n",
    "#combine stats from roi and buffer\n",
    "fc_stats_combined_all = fc_stats_combined.merge(fc_stats_combined_buffer) # combining alerts with others into one feature collection\n",
    "\n",
    "# convert to Pandas Dataframe\n",
    "df_combined = geemap.ee_to_pandas(fc_stats_combined_all) # limit of 5000 (unlikely to need more but i have code for it if needed)\n",
    "\n",
    "# export dataframe to csv\n",
    "df_combined.to_csv(path_or_buf=out_file_long,header=True,index=False)\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = time.time() - st\n",
    "\n",
    "if debug: print ('Total execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec10e289-42df-42f4-b576-ef216efe8356",
   "metadata": {},
   "source": [
    "##### ii): Create lookup tables for country allocation\n",
    "Approach is based on raster stats and listing the country for a specific geometry based on which has most overlap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375629ec-ef13-4c64-9c5c-cbb3563b8d2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Look up table linking country codes to country names (from GAUL feature collection) is stored here: scripts: create_country_lookup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb09fe-dcf8-4084-95aa-f8c586dfe78d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Make on-the-fly look up table to link country name to geo id based on raster stats\n",
    "- uses rasterised GAUL layer with admin codes as pixel values\n",
    "- for each geo id finds most common value in that geometry (i.e. \"mode\" statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8f51bc-be03-4c05-8337-942f06653803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m lookup_geo_id_to_GAUL_codes \u001b[38;5;241m=\u001b[39m lookup_geo_id_to_GAUL_codes\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADM0_CODE\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \u001b[38;5;66;03m# change names for a clean join \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# lookup_geo_id_to_GAUL_country_names = lookup_geo_id_to_GAUL_codes.merge(lookup_country_codes_to_names,on=\"ADM0_CODE\",how=\"inner\").drop(\"ADM0_CODE\",axis=1) # join geo id to the GAUL_lookup_table countaining \"Country_names\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m lookup_geo_id_to_ISO3 \u001b[38;5;241m=\u001b[39m \u001b[43mlookup_geo_id_to_GAUL_codes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookup_country_codes_to_ISO3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADM0_CODE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADM0_CODE\u001b[39m\u001b[38;5;124m\"\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# join geo id to the GAUL_lookup_table countaining \"Country_names\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:9843\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9824\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9825\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9826\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9839\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9840\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9841\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9844\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9852\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9857\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/merge.py:148\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 148\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/merge.py:741\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m (\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m    737\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/merge.py:1401\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1397\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1398\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1399\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1400\u001b[0m     ):\n\u001b[0;32m-> 1401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "fc_stats_country_codes = area_stats.reduceStatsIC(roi,\n",
    "                                  images_IC.filter(ee.Filter.eq(\"dataset_id\",16)),\n",
    "                                  reducer_choice)# all but alerts\n",
    "\n",
    "df_stats_country_codes = geemap.ee_to_pandas(fc_stats_country_codes) # limit of 5000 (unlikely to need more fpr demo but i have code for it if this happens)\n",
    "\n",
    "lookup_geo_id_to_GAUL_codes = df_stats_country_codes[df_stats_country_codes[\"dataset_name\"]==\"GAUL_boundaries_adm0_code_reproj\"]  #get mode stats for GAUL dataset\n",
    "\n",
    "lookup_geo_id_to_GAUL_codes = lookup_geo_id_to_GAUL_codes[[geo_id_column, 'mode']] # choose only columns needed\n",
    "\n",
    "lookup_geo_id_to_GAUL_codes = lookup_geo_id_to_GAUL_codes.rename(columns={\"mode\":\"ADM0_CODE\"}) # change names for a clean join \n",
    "\n",
    "lookup_geo_id_to_GAUL_country_names = lookup_geo_id_to_GAUL_codes.merge(lookup_country_codes_to_names,on=\"ADM0_CODE\",how=\"inner\").drop(\"ADM0_CODE\",axis=1) # join geo id to the GAUL_lookup_table countaining \"Country_names\"\n",
    "# lookup_geo_id_to_ISO3 = lookup_geo_id_to_GAUL_codes.merge(lookup_country_codes_to_ISO3,on=\"ADM0_CODE\",how=\"inner\").drop(\"ADM0_CODE\",axis=1) # join geo id to the GAUL_lookup_table countaining \"Country_names\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb5856-0a96-4399-ab5c-341c84eb3132",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### iii) Reformat results table\n",
    "- long to wide\n",
    "- convert to proportions \n",
    "- set presence only flags\n",
    "- add in country names (using lookup tables) to the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f4b376-8375-4670-8cb0-c9aaf96fa407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add proprtion column\n",
    "df_combined[\"percentage\"] = (df_combined[\"sum\"]/df_combined[geometry_area_column])*100\n",
    "\n",
    "#convert to wide format (one row per geo_id)\n",
    "df_wide_format = df_combined.pivot_table(index=[geo_id_column,geometry_area_column],columns=['dataset_name'],values=['percentage'])\n",
    "\n",
    "# # #tidy unwanted headers etc\n",
    "tidy_tables.tidy_dataframe_after_pivot(df_wide_format) #runs in place so no need to assign\n",
    "\n",
    "# convert positive results values to \"True\" for specific columns\n",
    "for column in flag_list: df_wide_format[column]=np.where(df_wide_format[column]>0,\"True\",\"-\")\n",
    "\n",
    "# # tidy output - decimal places\n",
    "for column in flag_list: df_wide_format[decimal_place_column_list]=df_wide_format[decimal_place_column_list].round(decimals=0, out=None).astype(int)\n",
    "\n",
    "df_wide_format=df_wide_format.reset_index()\n",
    "\n",
    "df_wide_format[geometry_area_column]=df_wide_format[geometry_area_column].round(decimals=1, out=None)\n",
    "\n",
    "# #joins country name based on majority overlap with country \n",
    "# if debug: print (columns_list)\n",
    "print(decimal_place_column_list)\n",
    "print(flag_list)\n",
    "\n",
    "df_wide_format = df_wide_format.merge(lookup_geo_id_to_GAUL_country_names,on=geo_id_column)\n",
    "df_wide_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31929f1c-b245-4bef-968f-64bdee8ef1ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### iv) Further reformatting and exporting\n",
    "- reorder columns\n",
    "- remove underscores in column titles\n",
    "- export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20836916-d664-4334-aa6c-47916823443a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reorder columns using list \n",
    "ordered_dataset_df= lookup_gee_datasets.sort_values(by=['datasets_order'])\n",
    "\n",
    "column_order_list = list(ordered_dataset_df[\"dataset_name\"])\n",
    "                         \n",
    "column_order_list.insert(0,geo_id_column) # add in the \"geo_id\" column into to datasets list\n",
    "\n",
    "column_order_list.insert(1,geometry_area_column)# add in to list the geometry area column\n",
    "\n",
    "column_order_list.remove(\"GAUL_boundaries_adm0_code_reproj\") # remove old column with \"mode\" values (not now relevant as have country names)\n",
    "\n",
    "column_order_list.insert(2,\"Country\")# add in to list the new column with country names\n",
    "\n",
    "df_wide_format= df_wide_format.reindex(columns=column_order_list) # reorder by list\n",
    "\n",
    "df_wide_format[\"Country\"]=np.where(df_wide_format[\"Country\"]==\"C�te d'Ivoire\",\"Côte d'Ivoire\",df_wide_format[\"Country\"])# TEMP fix on characters (encoding issues)\n",
    "df_wide_format[\"Country\"]=np.where(df_wide_format[\"Country\"]==\"R�union\",\"Réunion\",df_wide_format[\"Country\"])# TEMP fix on characters (encoding issues)\n",
    "\n",
    "# remove underscores in columns\n",
    "df_wide_format.columns = df_wide_format.columns.str.replace('_', ' ')\n",
    "\n",
    "# #export wide format csv\n",
    "df_wide_format.to_csv(path_or_buf=out_file_wide,header=True)\n",
    "\n",
    "# if debug: print (\"output csv: \", out_file_wide)\n",
    "\n",
    "#checks\n",
    "if debug: flag_list\n",
    "# if debug: print (columns_list)\n",
    "\n",
    "df_wide_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b512b0-f24b-4554-9d0b-8d34929804cd",
   "metadata": {},
   "source": [
    "#### Display layers\n",
    "\n",
    "##### Loop through image collection and loads layers to be added to the map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc82d7d-94aa-4e41-b321-c8d9daf43a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "visParams =  {'min': 0,'max': 1,'palette':['White','Green']}\n",
    "\n",
    "for i in range(images_IC.size().getInfo()):\n",
    "    \n",
    "    image_new = ee.Image(images_IC.toList(100,0).get(i))\n",
    "    \n",
    "    dataset_name = image_new.get(\"system:index\").getInfo()\n",
    "    \n",
    "    if debug: print (\"adding image\",i,\"-\",dataset_name)\n",
    "    Map.addLayer(image_new.gt(0).unmask(),visParams,dataset_name,0,1)\n",
    "    \n",
    "    \n",
    "Map.addLayer(roi,{},'roi ',1,1)\n",
    "# Map.addLayer(roi_alerts_buffer,{},'roi buffer zone')\n",
    "\n",
    "if debug: print (\"All layers added\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440a5615-0482-49a7-946e-3c99dff6f2a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Show on map and zoom to a specific feature based on index number in feature collection\n",
    " Layers visibility off by default - toggle on in top right corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3dfb2-91fc-4e78-a49e-85c7294c794c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number/index from list of ROI features - the selected feature is shown on the map. e.g., choose 0 for first in the list \n",
    "feature_to_centre_on = 1\n",
    "\n",
    "#choose how close to zoom to chosen polygon (1-24, where 24 is fully zoomed in) \n",
    "zoom_level = 16 \n",
    "\n",
    "single_feature_id = roi.aggregate_array(geo_id_column).get(feature_to_centre_on).getInfo()\n",
    "if debug: print (geo_id_column,single_feature_id)\n",
    "single_feature = ee.Feature(roi.filter(ee.Filter.eq(geo_id_column,single_feature_id)).first())\n",
    "\n",
    "Map.centerObject(single_feature,zoom_level)\n",
    "    \n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5049a9",
   "metadata": {},
   "source": [
    "### Logout (protected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51242cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = session.get(asset_registry_base + \"/logout\")\n",
    "# if debug: print (res.json())\n",
    "# res = session.get(user_registry_base + \"/logout\", cookies=session.cookies)\n",
    "# session.headers.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ef7cf",
   "metadata": {},
   "source": [
    "### Checking if Logged out correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dee3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirming the logout from Asset Registry by requesting a Protected route\n",
    "# req_body = {\n",
    "#     \"latitude\": 31.47704430446457,\n",
    "#     \"longitude\": 74.37510786779589\n",
    "# }\n",
    "# res = session.post(asset_registry_base + \"/fetch-fields-for-a-point\", json=req_body)\n",
    "# if debug: print (res.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07b78b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get all Domains (public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf8a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Fetching all the domains from the User Registry\n",
    "# res = session.get(asset_registry_base + \"/domains\")\n",
    "# if debug: print (res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11dedf3-235f-4614-9b51-b986d986692d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbc06b-6bf1-46ad-ad10-a5a10adc47c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
